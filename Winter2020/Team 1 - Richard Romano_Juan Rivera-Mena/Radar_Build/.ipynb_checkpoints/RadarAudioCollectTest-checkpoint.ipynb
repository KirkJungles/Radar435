{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as sig\n",
    "\n",
    "# Custom libraries\n",
    "import pulsetrain as pt\n",
    "import pulsenoise as pn\n",
    "import detection as det\n",
    "\n",
    "# Student Libary\n",
    "import lastname as GPD # Intials (George P. Burdell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([128, 128, 127, ..., 128, 128, 127], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([128, 128, 128, ..., 128, 128, 128], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([128, 128, 127, ..., 126, 126, 125], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([126, 126, 126, ..., 134, 134, 134], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([134, 134, 133, ..., 116, 115, 114], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([116, 116, 116, ..., 121, 118, 118], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average frame rate = 21 FPS\n",
      "stream closed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    Notebook for streaming data from a microphone in realtime\n",
    "    audio is captured using pyaudio\n",
    "    then converted from binary data to ints using struct\n",
    "    then displayed using matplotlib\n",
    "    scipy.fftpack computes the FFT\n",
    "    if you don't have pyaudio, then run\n",
    "    >>> pip install pyaudio\n",
    "    note: with 2048 samples per chunk, I'm getting 20FPS\n",
    "    when also running the spectrum, its about 15FPS\n",
    "\"\"\"\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('QT4Agg')\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "from pyqtgraph.Qt import QtGui, QtCore\n",
    "import pyqtgraph as pg\n",
    "import struct\n",
    "from scipy.fftpack import fft\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pylab import get_current_fig_manager\n",
    "\n",
    "\n",
    "class AudioStream(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        # stream constants\n",
    "        self.CHUNK = 1024 * 2\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 44100\n",
    "        self.pause = False\n",
    "\n",
    "        # stream object\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=self.FORMAT,\n",
    "            channels=self.CHANNELS,\n",
    "            rate=self.RATE,\n",
    "            input=True,\n",
    "            output=True,\n",
    "            frames_per_buffer=self.CHUNK,\n",
    "        )\n",
    "\n",
    "\n",
    "        # x variables for plotting\n",
    "        x = np.arange(0, 2 * self.CHUNK, 2)\n",
    "        xf = np.linspace(0, self.RATE, self.CHUNK)\n",
    "        # self.Rate = R_Unambg = stop, len_PRI = rate\n",
    "\n",
    "\n",
    "\n",
    "        print('stream started')\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        while frame_count <= 5:\n",
    "            data = self.stream.read(self.CHUNK, exception_on_overflow = False)\n",
    "            data_int = struct.unpack(str(2 * self.CHUNK) + 'B', data)\n",
    "            data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "            \n",
    "            display(data_np)\n",
    "            frame_count += 1\n",
    "\n",
    "        else:\n",
    "            self.fr = frame_count / (time.time() - start_time)\n",
    "            print('average frame rate = {:.0f} FPS'.format(self.fr))\n",
    "            self.exit_app()\n",
    "\n",
    "    def exit_app(self):\n",
    "        print('stream closed')\n",
    "        self.p.close(self.stream)\n",
    "\n",
    "    def onClick(self, event):\n",
    "        self.pause = True\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    AudioStream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e5880a159abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Envelope detect the signals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlen_PRI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmain_trace_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvelope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_np\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Replace with X Corr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# -------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_np' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Detection Section\n",
    "# Envelope detect the signals\n",
    "len_PRI = 2048\n",
    "main_trace_env = det.envelope(data_np) # Replace with X Corr\n",
    "\n",
    "# -------------------------------\n",
    "# Gate the signal & sum them up for \n",
    "# provide n observation effects\n",
    "n_obs_main_trace_env = main_trace_env.reshape(K_pulses+1, len_PRI)\n",
    "# add them all together\n",
    "n_obs_main_trace_env = n_obs_main_trace_env.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "dBm = -100 #dBm\n",
    "scalar = 1e-3 * np.power(10,(dBm/10))\n",
    "#height = scalar\n",
    "\n",
    "peaks, _ = find_peaks(n_obs_main_trace_env, height=scalar, distance=5e3)\n",
    "# peaks2 = np.clip(n_obs_main_trace_env, a_min=scalar, a_max=None)\n",
    "peaks2 = peaks * R_unamb/(len(n_obs_main_trace_env))\n",
    "display(R_unamb/(len(n_obs_main_trace_env)))\n",
    "display(R_unamb/len_PRI)\n",
    "display(len_PRI)\n",
    "target_ranges.sort()\n",
    "display(peaks2) # Indices\n",
    "display(target_ranges)\n",
    "\n",
    "# Dont use clips...build own clips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the distance vector\n",
    "nsamps = len(n_obs_main_trace_env)\n",
    "x = np.linspace(0,R_unamb, nsamps)\n",
    "dx = R_unamb/(len(n_obs_main_trace_env))\n",
    "display(R_unamb)\n",
    "display(nsamps)\n",
    "\n",
    "plt.semilogy(x/1e3,n_obs_main_trace_env)\n",
    "plt.semilogy(peaks*dx/1e3,n_obs_main_trace_env[peaks], 'x')\n",
    "plt.title('This is my title')\n",
    "plt.xlabel('Distance in km')\n",
    "plt.ylabel('Power in Watts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.signal.spectogram\n",
    "\n",
    "k*lamda + theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
